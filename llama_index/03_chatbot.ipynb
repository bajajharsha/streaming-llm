{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshabajaj/Desktop/LLMs/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/h_/jqpt8zm51rlcypx1vxq_dckr0000gn/T/ipykernel_36966/2363923416.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    api_key=\"AIzaSyDYn0Vm5GFCk6g2WWtSPoejyYtl8rmaPpw\",  # uses GOOGLE_API_KEY env var by default\n",
    ")\n",
    "\n",
    "data = SimpleDirectoryReader(input_dir=\"../data\").load_data()\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "embed_model=LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Configure settings globally\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "index = VectorStoreIndex.from_documents(data)\n",
    "\n",
    "chat_engine = index.as_chat_engine(chat_mode=\"best\", llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step dd0dc4d8-5938-4c8b-8f8f-25f2a7b7f9f7. Step input: hello\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me understand what the user wants.  Since the user only said \"hello\", I cannot infer their intent.  I will respond with a greeting.\n",
      "Answer: Hello! How can I help you today?\n",
      "\u001b[0mAgent: Hello! How can I help you today?\n",
      "> Running step 7f927148-b6b1-431c-afef-e0821ac1e7bd. Step input: you tell, how can you help me?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to explain my capabilities.  I will not use any tools for this.\n",
      "Answer: I can help you with a variety of tasks, including answering questions, providing summaries of text, and performing other types of analysis.  I can access and process information from a large knowledge base.  Just ask me your question or describe the task you need help with.\n",
      "\u001b[0mAgent: I can help you with a variety of tasks, including answering questions, providing summaries of text, and performing other types of analysis.  I can access and process information from a large knowledge base.  Just ask me your question or describe the task you need help with.\n",
      "> Running step 9034125c-0363-48e3-a1f4-6cb32babe388. Step input: hello?\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Hello there!  How can I assist you today?\n",
      "\n",
      "\u001b[0mAgent: Hello there!  How can I assist you today?\n",
      "\n",
      "> Running step 3c87984e-d51f-4911-b450-a8bb1ed6c5ef. Step input: who published the paper \"attention is all you need\"?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'Who published the paper \"Attention is all you need\"?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: This question cannot be answered from the given source.\n",
      "\n",
      "\u001b[0m> Running step 290c247f-b6d3-4f1f-9a12-00ad7907d184. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I cannot answer the question with the provided tools.\n",
      "Answer: I apologize, but I am unable to answer your question using my current resources.  My knowledge base does not contain the information needed to determine who published the paper \"Attention is all you need\".  You may be able to find this information through a web search engine like Google Scholar.\n",
      "\u001b[0mAgent: I apologize, but I am unable to answer your question using my current resources.  My knowledge base does not contain the information needed to determine who published the paper \"Attention is all you need\".  You may be able to find this information through a web search engine like Google Scholar.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text_input = input(\"User: \")\n",
    "    if text_input == \"exit\":\n",
    "        break\n",
    "    response = chat_engine.chat(text_input)\n",
    "    print(f\"Agent: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
